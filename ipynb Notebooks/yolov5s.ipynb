{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12213974,"sourceType":"datasetVersion","datasetId":7694479},{"sourceId":12214110,"sourceType":"datasetVersion","datasetId":7694596},{"sourceId":12228362,"sourceType":"datasetVersion","datasetId":7704497}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom sklearn.model_selection import train_test_split\n\n#  CONFIGURATION\nimage_dir = \"/kaggle/input/original/train/images\"\nlabel_dir = \"/kaggle/input/original/train/labels\"\nbg_image_dir = \"/kaggle/input/background/background_only\"\nbg_label_dir = \"/kaggle/input/background/background_only_labels\"\noutput_base = \"/kaggle/working/combined_split\"\nnum_bg_to_add = 180  # 👈 change this as needed\n\n#  Get only labeled image base names (non-empty label .txts)\nimage_basenames = []\nfor fname in os.listdir(label_dir):\n    if fname.endswith(\".txt\"):\n        with open(os.path.join(label_dir, fname)) as f:\n            if f.read().strip():\n                image_basenames.append(fname.replace(\".txt\", \"\"))\n\n#  Split labeled data\ntrain_val, test = train_test_split(image_basenames, test_size=0.1, random_state=42)\ntrain, val = train_test_split(train_val, test_size=0.2222, random_state=42)  # ~20% val\n\n#  Prepare output folders\ndef copy_split(split_names, split_type):\n    img_out = os.path.join(output_base, split_type, \"images\")\n    lbl_out = os.path.join(output_base, split_type, \"labels\")\n    os.makedirs(img_out, exist_ok=True)\n    os.makedirs(lbl_out, exist_ok=True)\n\n    for name in split_names:\n        shutil.copy(os.path.join(image_dir, f\"{name}.jpg\"), os.path.join(img_out, f\"{name}.jpg\"))\n        shutil.copy(os.path.join(label_dir, f\"{name}.txt\"), os.path.join(lbl_out, f\"{name}.txt\"))\n\ncopy_split(train, \"train\")\ncopy_split(val, \"valid\")\ncopy_split(test, \"test\")\n\n#  Select & copy a limited number of background-only images to training set\nbg_images = [f for f in os.listdir(bg_image_dir) if f.endswith(\".jpg\")]\nrandom.shuffle(bg_images)\nbg_images_to_add = bg_images[:num_bg_to_add]\n\ntrain_img_dir = os.path.join(output_base, \"train/images\")\ntrain_lbl_dir = os.path.join(output_base, \"train/labels\")\n\nfor img_name in bg_images_to_add:\n    base = os.path.splitext(img_name)[0]\n    img_path = os.path.join(bg_image_dir, img_name)\n    lbl_path = os.path.join(bg_label_dir, f\"{base}.txt\")\n    shutil.copy(img_path, os.path.join(train_img_dir, img_name))\n    shutil.copy(lbl_path, os.path.join(train_lbl_dir, f\"{base}.txt\"))\n\nprint(f\"✅ Final split: {len(train)} train (+{len(bg_images_to_add)} bg), {len(val)} val, {len(test)} test\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-20T12:43:46.984894Z","iopub.execute_input":"2025-06-20T12:43:46.985150Z","iopub.status.idle":"2025-06-20T12:44:05.293967Z","shell.execute_reply.started":"2025-06-20T12:43:46.985113Z","shell.execute_reply":"2025-06-20T12:44:05.293380Z"}},"outputs":[{"name":"stdout","text":"✅ Final split: 346 train (+180 bg), 99 val, 50 test\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"yaml_content = \"\"\"\ntrain: /kaggle/working/combined_split/train/images\nval: /kaggle/working/combined_split/valid/images\ntest: /kaggle/working/combined_split/test/images\n\nnc: 4\nnames: ['Absence_Head', 'Absence_Tail', 'Head_Rivet', 'Tail_Rivet']\n\"\"\"\n\nyaml_path = \"/kaggle/working/rivet_detection.yaml\"\nwith open(yaml_path, \"w\") as f:\n    f.write(yaml_content.strip())\n\nprint(f\"✅ YAML file written to: {yaml_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T12:44:09.345477Z","iopub.execute_input":"2025-06-20T12:44:09.346111Z","iopub.status.idle":"2025-06-20T12:44:09.350767Z","shell.execute_reply.started":"2025-06-20T12:44:09.346080Z","shell.execute_reply":"2025-06-20T12:44:09.350150Z"}},"outputs":[{"name":"stdout","text":"✅ YAML file written to: /kaggle/working/rivet_detection.yaml\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install ultralytics --upgrade --quiet\n\nimport os\nfrom ultralytics import YOLO\n\n\nDATA_YAML_PATH = \"/kaggle/working/rivet_detection.yaml\"  \nmodel = YOLO(\"yolov5s.pt\").to(\"cuda\")  \n\n# Train the model\nmodel.train(\n    data=DATA_YAML_PATH,\n    device='cuda',\n    epochs=100,\n    batch=8,\n    imgsz=896,         \n    patience=20,\n    optimizer='SGD',\n    lr0=0.002,\n    lrf=0.1,\n    weight_decay=0.0005,\n    cos_lr=True,\n    save_period=10,\n    workers=4,\n    amp=True,\n\n    mosaic=1.0,\n    auto_augment='randaugment',\n    augment=True,\n\n    hsv_h=0.01,\n    hsv_s=0.8,\n    hsv_v=0.4,\n\n    flipud=0.5,\n    fliplr=0.5,\n\n    translate=0.1,\n    scale=0.3,\n    shear=0.05,\n    perspective=0.001,\n    degrees=5.0,\n\n    mixup=0.1,\n    erasing=0.0,\n    close_mosaic=2,\n    dropout=0.1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T11:49:39.850019Z","iopub.execute_input":"2025-06-20T11:49:39.850229Z","execution_failed":"2025-06-20T11:50:44.699Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nPRO TIP 💡 Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\nYOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 17.7M/17.7M [00:00<00:00, 158MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.157 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=2, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/rivet_detection.yaml, degrees=5.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.1, dynamic=False, embed=None, epochs=100, erasing=0.0, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.01, hsv_s=0.8, hsv_v=0.4, imgsz=896, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.002, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov5s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=20, perspective=0.001, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.3, seed=0, shear=0.05, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 17.3MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=4\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n 24        [17, 20, 23]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \nYOLOv5s summary: 153 layers, 9,123,740 parameters, 9,123,724 gradients, 24.0 GFLOPs\n\nTransferred 421/427 items from pretrained weights\nFreezing layer 'model.24.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5.35M/5.35M [00:00<00:00, 71.5MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2217.2±1518.4 MB/s, size: 212.2 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/combined_split/train/labels... 526 images, 180 backgrounds, 0 corrupt: 100%|██████████| 526/526 [00:00<00:00, 1483.50it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/combined_split/train/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1297.9±973.1 MB/s, size: 340.7 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/combined_split/valid/labels... 99 images, 0 backgrounds, 0 corrupt: 100%|██████████| 99/99 [00:00<00:00, 1634.52it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/combined_split/valid/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics --upgrade --quiet\nimport os\nimport shutil\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\n\n# Step 1: Define paths\nweights_path = \"/kaggle/input/weight-yolov5/best.pt\"  # Change this to your actual path\npredict_dir = \"/kaggle/working/predict\"\ntest_images_dir = \"/kaggle/working/combined_split/test/images\"\nyaml_path = \"/kaggle/working/rivet_detection.yaml\"\n\n# Step 2: Create predict folder\nos.makedirs(predict_dir, exist_ok=True)\n\n# Step 3: Copy weights to working directory if needed\nworking_weights_path = \"/kaggle/input/weight-yolov5/best.pt\"\nif not os.path.exists(working_weights_path):\n    shutil.copy(weights_path, working_weights_path)\n\n# Step 4: Load the model\nmodel = YOLO(working_weights_path)\n\n# Step 5: Run prediction on test images\nresults = model.predict(\n    source=test_images_dir,\n    save=True,\n    save_txt=True,\n    conf=0.50,\n    imgsz=896,\n    project=predict_dir,\n    name=\"predict_results\",\n    exist_ok=True\n)\n\n# Step 6: Run validation on test set to get confusion matrix\nmetrics = model.val(\n    data=yaml_path,\n    split='test',\n    save_json=True,\n    plots=True,\n    project=predict_dir,\n    name=\"val_results\",\n    exist_ok=True\n)\n\nprint(\"✅ Inference complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T12:47:36.699530Z","iopub.execute_input":"2025-06-20T12:47:36.699859Z","iopub.status.idle":"2025-06-20T12:47:59.165174Z","shell.execute_reply.started":"2025-06-20T12:47:36.699828Z","shell.execute_reply":"2025-06-20T12:47:59.164478Z"}},"outputs":[{"name":"stdout","text":"\nimage 1/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0005_jpg.rf.2dd9fc700d1f491869c790bc6592912e_aug_1.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 24.0ms\nimage 2/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0005_jpg.rf.2dd9fc700d1f491869c790bc6592912e_aug_3.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 24.0ms\nimage 3/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0007_jpg.rf.36efe4178203e6b12bc53223001f5c4e.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 24.0ms\nimage 4/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0007_jpg.rf.36efe4178203e6b12bc53223001f5c4e_aug_2.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 23.9ms\nimage 5/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 23.9ms\nimage 6/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5_aug_3.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 23.4ms\nimage 7/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5_aug_7.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 20.0ms\nimage 8/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5_aug_8.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 19.9ms\nimage 9/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5_aug_9.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 19.9ms\nimage 10/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0011_jpg.rf.d064d892b6063d23edba108f81ba01dc_aug_4.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 19.9ms\nimage 11/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0012_jpg.rf.15476ca3fa8cec2879e24327a0ad24a2.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 20.0ms\nimage 12/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0014_jpg.rf.e57903f2324daaef355c6ffbda80e71d_aug_1.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 19.9ms\nimage 13/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0014_jpg.rf.e57903f2324daaef355c6ffbda80e71d_aug_6.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 19.9ms\nimage 14/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0014_jpg.rf.e57903f2324daaef355c6ffbda80e71d_aug_7.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 19.5ms\nimage 15/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0015_jpg.rf.a743dec6400737062c01c198ddd25e03_aug_6.jpg: 896x896 4 Head_Rivets, 5 Tail_Rivets, 18.1ms\nimage 16/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0016_jpg.rf.b832c98c2aa37f4b84aaf255b7fe80e5_aug_5.jpg: 896x896 5 Head_Rivets, 6 Tail_Rivets, 18.0ms\nimage 17/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0017_jpg.rf.455029f7e861fdc94c4f6c7adc2746cd_aug_5.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 18.1ms\nimage 18/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0017_jpg.rf.455029f7e861fdc94c4f6c7adc2746cd_aug_6.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 18.0ms\nimage 19/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0019_jpg.rf.db9af3c22d1fe58852e1caf601905d23_aug_5.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.6ms\nimage 20/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0024_jpg.rf.609e1392d6106bbbf9e8114ff7743e32_aug_9.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 17.6ms\nimage 21/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0026_jpg.rf.e78e4e49ac8c9461bf9a6302685e650e_aug_1.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.6ms\nimage 22/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0026_jpg.rf.e78e4e49ac8c9461bf9a6302685e650e_aug_4.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.6ms\nimage 23/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0026_jpg.rf.e78e4e49ac8c9461bf9a6302685e650e_aug_9.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.4ms\nimage 24/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0027_jpg.rf.6a5a5fe0b36c628c3a6af3b3dbcffbd5.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.4ms\nimage 25/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0029_jpg.rf.8a77e3a8843bf62a44ed8fd514ee0290_aug_7.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.3ms\nimage 26/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0030_jpg.rf.4c1c271d75a20b16637a66411f2f64df_aug_7.jpg: 896x896 5 Head_Rivets, 6 Tail_Rivets, 17.4ms\nimage 27/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0031_jpg.rf.ff9e542533f838b8cf2d633aed006a73_aug_6.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.4ms\nimage 28/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0031_jpg.rf.ff9e542533f838b8cf2d633aed006a73_aug_8.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.3ms\nimage 29/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0032_jpg.rf.42db5fe8804ca5676aa2531883cb8902_aug_8.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 17.4ms\nimage 30/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0034_jpg.rf.33d666968b35df76b4a93f84f4528eee_aug_2.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.3ms\nimage 31/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0034_jpg.rf.33d666968b35df76b4a93f84f4528eee_aug_6.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.3ms\nimage 32/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0037_jpg.rf.b204e298bae76376bba45a84f1187890_aug_2.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 16.2ms\nimage 33/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0037_jpg.rf.b204e298bae76376bba45a84f1187890_aug_9.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 16.3ms\nimage 34/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0038_jpg.rf.c4e4c95e8203878c3f8a03560554cf54_aug_7.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 15.8ms\nimage 35/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0038_jpg.rf.c4e4c95e8203878c3f8a03560554cf54_aug_8.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 15.8ms\nimage 36/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0042_jpg.rf.3243e439b740dd43d69f674bd2629a82.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 37/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0004_jpg.rf.923475309e97e5561dee9252b710ccd6.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 38/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0004_jpg.rf.923475309e97e5561dee9252b710ccd6_aug_9.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.7ms\nimage 39/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_1.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 40/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_2.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 41/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_3.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.3ms\nimage 42/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_8.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.3ms\nimage 43/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_9.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.0ms\nimage 44/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0006_jpg.rf.71ffe86a6471f7251b1d76ebf95eb326_aug_2.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.0ms\nimage 45/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0009_jpg.rf.64856461ea21914a5b651646d9bd6258_aug_8.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.0ms\nimage 46/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0010_jpg.rf.c39013315ee30f7fb1196dc92affb4cf_aug_1.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.0ms\nimage 47/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0010_jpg.rf.c39013315ee30f7fb1196dc92affb4cf_aug_8.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 6 Tail_Rivets, 15.0ms\nimage 48/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0011_jpg.rf.cf46568e26825550194b1edd28cd3a8d_aug_0.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 14.9ms\nimage 49/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0011_jpg.rf.cf46568e26825550194b1edd28cd3a8d_aug_3.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.0ms\nimage 50/50 /kaggle/working/combined_split/test/images/WhatsApp-Image-2025-06-03-at-17_38_11_83d8e6cd_jpg.rf.5b300a797cac127b21c14556837fb8e8_aug_0.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 15.0ms\nSpeed: 3.9ms preprocess, 17.9ms inference, 9.3ms postprocess per image at shape (1, 3, 896, 896)\nResults saved to \u001b[1m/kaggle/working/predict/predict_results\u001b[0m\n50 labels saved to /kaggle/working/predict/predict_results/labels\nUltralytics 8.3.157 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 17.2MB/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2778.7±632.4 MB/s, size: 651.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/combined_split/test/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|██████████| 50/50 [00:00<00:00, 668.04it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/combined_split/test/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:05<00:00,  1.30s/it]\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         50        600      0.993       0.96      0.991      0.649\n          Absence_Head          7          7          1      0.849      0.978      0.592\n          Absence_Tail         20         20      0.976          1      0.995      0.677\n            Head_Rivet         50        292      0.998      0.997      0.995      0.691\n            Tail_Rivet         50        281      0.997      0.993      0.995      0.637\nSpeed: 11.6ms preprocess, 23.4ms inference, 0.0ms loss, 18.0ms postprocess per image\nSaving /kaggle/working/predict/val_results/predictions.json...\nResults saved to \u001b[1m/kaggle/working/predict/val_results\u001b[0m\n✅ Inference complete.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import shutil\n\n# Zip the predict_tta folder\nshutil.make_archive(\"/kaggle/working/predict/predict_results\", 'zip', \"/kaggle/working/predict\")\nprint(\"✅ Folder zipped as /kaggle/working/predict.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T12:48:17.262427Z","iopub.execute_input":"2025-06-20T12:48:17.263279Z","iopub.status.idle":"2025-06-20T12:48:18.451963Z","shell.execute_reply.started":"2025-06-20T12:48:17.263245Z","shell.execute_reply":"2025-06-20T12:48:18.451172Z"}},"outputs":[{"name":"stdout","text":"✅ Folder zipped as /kaggle/working/predict.zip\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}