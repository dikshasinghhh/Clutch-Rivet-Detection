{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12213974,"sourceType":"datasetVersion","datasetId":7694479},{"sourceId":12214110,"sourceType":"datasetVersion","datasetId":7694596},{"sourceId":12227788,"sourceType":"datasetVersion","datasetId":7704096}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom sklearn.model_selection import train_test_split\n\n# CONFIGURATION\nimage_dir = \"/kaggle/input/original/train/images\"\nlabel_dir = \"/kaggle/input/original/train/labels\"\nbg_image_dir = \"/kaggle/input/background/background_only\"\nbg_label_dir = \"/kaggle/input/background/background_only_labels\"\noutput_base = \"/kaggle/working/combined_split\"\nnum_bg_to_add = 180  # ðŸ‘ˆ change this as needed\n\n# Step 1: Get only labeled image base names (non-empty label .txts)\nimage_basenames = []\nfor fname in os.listdir(label_dir):\n    if fname.endswith(\".txt\"):\n        with open(os.path.join(label_dir, fname)) as f:\n            if f.read().strip():\n                image_basenames.append(fname.replace(\".txt\", \"\"))\n\n#  Step 2: Split labeled data\ntrain_val, test = train_test_split(image_basenames, test_size=0.1, random_state=42)\ntrain, val = train_test_split(train_val, test_size=0.2222, random_state=42)  # ~20% val\n\n# Step 3: Prepare output folders\ndef copy_split(split_names, split_type):\n    img_out = os.path.join(output_base, split_type, \"images\")\n    lbl_out = os.path.join(output_base, split_type, \"labels\")\n    os.makedirs(img_out, exist_ok=True)\n    os.makedirs(lbl_out, exist_ok=True)\n\n    for name in split_names:\n        shutil.copy(os.path.join(image_dir, f\"{name}.jpg\"), os.path.join(img_out, f\"{name}.jpg\"))\n        shutil.copy(os.path.join(label_dir, f\"{name}.txt\"), os.path.join(lbl_out, f\"{name}.txt\"))\n\ncopy_split(train, \"train\")\ncopy_split(val, \"valid\")\ncopy_split(test, \"test\")\n\n#  Step 4: Select & copy a limited number of background-only images to training set\nbg_images = [f for f in os.listdir(bg_image_dir) if f.endswith(\".jpg\")]\nrandom.shuffle(bg_images)\nbg_images_to_add = bg_images[:num_bg_to_add]\n\ntrain_img_dir = os.path.join(output_base, \"train/images\")\ntrain_lbl_dir = os.path.join(output_base, \"train/labels\")\n\nfor img_name in bg_images_to_add:\n    base = os.path.splitext(img_name)[0]\n    img_path = os.path.join(bg_image_dir, img_name)\n    lbl_path = os.path.join(bg_label_dir, f\"{base}.txt\")\n    shutil.copy(img_path, os.path.join(train_img_dir, img_name))\n    shutil.copy(lbl_path, os.path.join(train_lbl_dir, f\"{base}.txt\"))\n\nprint(f\"âœ… Final split: {len(train)} train (+{len(bg_images_to_add)} bg), {len(val)} val, {len(test)} test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T11:39:43.851582Z","iopub.execute_input":"2025-06-20T11:39:43.851784Z","iopub.status.idle":"2025-06-20T11:40:01.601423Z","shell.execute_reply.started":"2025-06-20T11:39:43.851767Z","shell.execute_reply":"2025-06-20T11:40:01.600617Z"}},"outputs":[{"name":"stdout","text":"âœ… Final split: 346 train (+180 bg), 99 val, 50 test\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"yaml_content = \"\"\"\ntrain: /kaggle/working/combined_split/train/images\nval: /kaggle/working/combined_split/valid/images\ntest: /kaggle/working/combined_split/test/images\n\nnc: 4\nnames: ['Absence_Head', 'Absence_Tail', 'Head_Rivet', 'Tail_Rivet']\n\"\"\"\n\nyaml_path = \"/kaggle/working/rivet_detection.yaml\"\nwith open(yaml_path, \"w\") as f:\n    f.write(yaml_content.strip())\n\nprint(f\"âœ… YAML file written to: {yaml_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T11:40:24.497473Z","iopub.execute_input":"2025-06-20T11:40:24.497744Z","iopub.status.idle":"2025-06-20T11:40:24.502780Z","shell.execute_reply.started":"2025-06-20T11:40:24.497722Z","shell.execute_reply":"2025-06-20T11:40:24.502000Z"}},"outputs":[{"name":"stdout","text":"âœ… YAML file written to: /kaggle/working/rivet_detection.yaml\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install ultralytics --upgrade --quiet\n\nimport os\nfrom ultralytics import YOLO\n\n\nDATA_YAML_PATH = \"/kaggle/working/rivet_detection.yaml\"  \nmodel = YOLO(\"yolov8s.pt\").to(\"cuda\")  \n\n# Train the model\nmodel.train(\n    data=DATA_YAML_PATH,\n    device='cuda',\n    epochs=100,\n    batch=8,\n    imgsz=896,         \n    patience=20,\n    optimizer='SGD',\n    lr0=0.002,\n    lrf=0.1,\n    weight_decay=0.0005,\n    cos_lr=True,\n    save_period=10,\n    workers=4,\n    amp=True,\n\n    mosaic=1.0,\n    auto_augment='randaugment',\n    augment=True,\n\n    hsv_h=0.01,\n    hsv_s=0.8,\n    hsv_v=0.4,\n\n    flipud=0.5,\n    fliplr=0.5,\n\n    translate=0.1,\n    scale=0.3,\n    shear=0.05,\n    perspective=0.001,\n    degrees=5.0,\n\n    mixup=0.1,\n    erasing=0.0,\n    close_mosaic=2,\n    dropout=0.1,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics --upgrade --quiet\nimport os\nimport shutil\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\n\n# Step 1: Define paths\nweights_path = \"/kaggle/input/weight-v8/best.pt\"  \npredict_dir = \"/kaggle/working/predict\"\ntest_images_dir = \"/kaggle/working/combined_split/test/images\"\nyaml_path = \"/kaggle/working/rivet_detection.yaml\"\n\n# Step 2: Create predict folder\nos.makedirs(predict_dir, exist_ok=True)\n\n# Step 3: Copy weights to working directory if needed\nworking_weights_path = \"/kaggle/input/weight-v8/best.pt\"\nif not os.path.exists(working_weights_path):\n    shutil.copy(weights_path, working_weights_path)\n\n# Step 4: Load the model\nmodel = YOLO(working_weights_path)\n\n# Step 5: Run prediction on test images\nresults = model.predict(\n    source=test_images_dir,\n    save=True,\n    save_txt=True,\n    conf=0.50,\n    imgsz=896,\n    project=predict_dir,\n    name=\"predict_results\",\n    exist_ok=True\n)\n\n# Step 6: Run validation on test set to get confusion matrix\nmetrics = model.val(\n    data=yaml_path,\n    split='test',\n    save_json=True,\n    plots=True,\n    project=predict_dir,\n    name=\"val_results\",\n    exist_ok=True\n)\n\nprint(\"âœ… Inference complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T11:42:45.428176Z","iopub.execute_input":"2025-06-20T11:42:45.428743Z","iopub.status.idle":"2025-06-20T11:43:01.045258Z","shell.execute_reply.started":"2025-06-20T11:42:45.428712Z","shell.execute_reply":"2025-06-20T11:43:01.044409Z"}},"outputs":[{"name":"stdout","text":"\nimage 1/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0005_jpg.rf.2dd9fc700d1f491869c790bc6592912e_aug_1.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 26.4ms\nimage 2/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0005_jpg.rf.2dd9fc700d1f491869c790bc6592912e_aug_3.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 26.5ms\nimage 3/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0007_jpg.rf.36efe4178203e6b12bc53223001f5c4e.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 26.4ms\nimage 4/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0007_jpg.rf.36efe4178203e6b12bc53223001f5c4e_aug_2.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 26.5ms\nimage 5/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 20.2ms\nimage 6/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5_aug_3.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 20.1ms\nimage 7/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5_aug_7.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 20.1ms\nimage 8/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5_aug_8.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 20.1ms\nimage 9/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0009_jpg.rf.bc224a81eb1b115382dd6b58dc81aad5_aug_9.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 18.9ms\nimage 10/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0011_jpg.rf.d064d892b6063d23edba108f81ba01dc_aug_4.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 19.0ms\nimage 11/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0012_jpg.rf.15476ca3fa8cec2879e24327a0ad24a2.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 18.9ms\nimage 12/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0014_jpg.rf.e57903f2324daaef355c6ffbda80e71d_aug_1.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 19.0ms\nimage 13/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0014_jpg.rf.e57903f2324daaef355c6ffbda80e71d_aug_6.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 18.9ms\nimage 14/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0014_jpg.rf.e57903f2324daaef355c6ffbda80e71d_aug_7.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 19.0ms\nimage 15/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0015_jpg.rf.a743dec6400737062c01c198ddd25e03_aug_6.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 19.1ms\nimage 16/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0016_jpg.rf.b832c98c2aa37f4b84aaf255b7fe80e5_aug_5.jpg: 896x896 5 Head_Rivets, 6 Tail_Rivets, 19.1ms\nimage 17/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0017_jpg.rf.455029f7e861fdc94c4f6c7adc2746cd_aug_5.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 18.0ms\nimage 18/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0017_jpg.rf.455029f7e861fdc94c4f6c7adc2746cd_aug_6.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 18.0ms\nimage 19/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0019_jpg.rf.db9af3c22d1fe58852e1caf601905d23_aug_5.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.7ms\nimage 20/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0024_jpg.rf.609e1392d6106bbbf9e8114ff7743e32_aug_9.jpg: 896x896 1 Absence_Head, 5 Head_Rivets, 6 Tail_Rivets, 17.7ms\nimage 21/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0026_jpg.rf.e78e4e49ac8c9461bf9a6302685e650e_aug_1.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.6ms\nimage 22/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0026_jpg.rf.e78e4e49ac8c9461bf9a6302685e650e_aug_4.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.6ms\nimage 23/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0026_jpg.rf.e78e4e49ac8c9461bf9a6302685e650e_aug_9.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.5ms\nimage 24/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0027_jpg.rf.6a5a5fe0b36c628c3a6af3b3dbcffbd5.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.3ms\nimage 25/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0029_jpg.rf.8a77e3a8843bf62a44ed8fd514ee0290_aug_7.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 17.3ms\nimage 26/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0030_jpg.rf.4c1c271d75a20b16637a66411f2f64df_aug_7.jpg: 896x896 2 Absence_Heads, 5 Head_Rivets, 6 Tail_Rivets, 16.2ms\nimage 27/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0031_jpg.rf.ff9e542533f838b8cf2d633aed006a73_aug_6.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 16.3ms\nimage 28/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0031_jpg.rf.ff9e542533f838b8cf2d633aed006a73_aug_8.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 16.1ms\nimage 29/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0032_jpg.rf.42db5fe8804ca5676aa2531883cb8902_aug_8.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 16.0ms\nimage 30/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0034_jpg.rf.33d666968b35df76b4a93f84f4528eee_aug_2.jpg: 896x896 5 Head_Rivets, 7 Tail_Rivets, 16.1ms\nimage 31/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0034_jpg.rf.33d666968b35df76b4a93f84f4528eee_aug_6.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 16.0ms\nimage 32/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0037_jpg.rf.b204e298bae76376bba45a84f1187890_aug_2.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 16.0ms\nimage 33/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0037_jpg.rf.b204e298bae76376bba45a84f1187890_aug_9.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 15.8ms\nimage 34/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0038_jpg.rf.c4e4c95e8203878c3f8a03560554cf54_aug_7.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 15.8ms\nimage 35/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0038_jpg.rf.c4e4c95e8203878c3f8a03560554cf54_aug_8.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 15.8ms\nimage 36/50 /kaggle/working/combined_split/test/images/IMG-20250525-WA0042_jpg.rf.3243e439b740dd43d69f674bd2629a82.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 37/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0004_jpg.rf.923475309e97e5561dee9252b710ccd6.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 38/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0004_jpg.rf.923475309e97e5561dee9252b710ccd6_aug_9.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 39/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_1.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 40/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_2.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 41/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_3.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.8ms\nimage 42/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_8.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.7ms\nimage 43/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0005_jpg.rf.1505196a2f9f9fafe0609ea90cdc9316_aug_9.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.3ms\nimage 44/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0006_jpg.rf.71ffe86a6471f7251b1d76ebf95eb326_aug_2.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.3ms\nimage 45/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0009_jpg.rf.64856461ea21914a5b651646d9bd6258_aug_8.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.3ms\nimage 46/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0010_jpg.rf.c39013315ee30f7fb1196dc92affb4cf_aug_1.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.3ms\nimage 47/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0010_jpg.rf.c39013315ee30f7fb1196dc92affb4cf_aug_8.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.3ms\nimage 48/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0011_jpg.rf.cf46568e26825550194b1edd28cd3a8d_aug_0.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.3ms\nimage 49/50 /kaggle/working/combined_split/test/images/IMG-20250603-WA0011_jpg.rf.cf46568e26825550194b1edd28cd3a8d_aug_3.jpg: 896x896 1 Absence_Tail, 6 Head_Rivets, 5 Tail_Rivets, 15.3ms\nimage 50/50 /kaggle/working/combined_split/test/images/WhatsApp-Image-2025-06-03-at-17_38_11_83d8e6cd_jpg.rf.5b300a797cac127b21c14556837fb8e8_aug_0.jpg: 896x896 6 Head_Rivets, 6 Tail_Rivets, 15.3ms\nSpeed: 4.0ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 896, 896)\nResults saved to \u001b[1m/kaggle/working/predict/predict_results\u001b[0m\n50 labels saved to /kaggle/working/predict/predict_results/labels\nUltralytics 8.3.157 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 16.4MB/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3216.8Â±378.1 MB/s, size: 494.0 KB)\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/combined_split/test/labels... 50 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 589.57it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/combined_split/test/labels.cache\n","output_type":"stream"},{"name":"stderr","text":"\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.47s/it]\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all         50        600      0.952      0.995      0.991      0.684\n          Absence_Head          7          7      0.873      0.984      0.978      0.651\n          Absence_Tail         20         20      0.964          1      0.995      0.753\n            Head_Rivet         50        292      0.992          1      0.995      0.692\n            Tail_Rivet         50        281      0.977      0.996      0.995       0.64\nSpeed: 12.0ms preprocess, 25.7ms inference, 0.0ms loss, 25.7ms postprocess per image\nSaving /kaggle/working/predict/val_results/predictions.json...\nResults saved to \u001b[1m/kaggle/working/predict/val_results\u001b[0m\nâœ… Inference complete.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import shutil\n\n# Zip the predict_tta folder\nshutil.make_archive(\"/kaggle/working/predict/predict_results\", 'zip', \"/kaggle/working/predict\")\nprint(\"âœ… Folder zipped as /kaggle/working/predict.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T11:46:49.424367Z","iopub.execute_input":"2025-06-20T11:46:49.425152Z","iopub.status.idle":"2025-06-20T11:46:50.591552Z","shell.execute_reply.started":"2025-06-20T11:46:49.425120Z","shell.execute_reply":"2025-06-20T11:46:50.590787Z"}},"outputs":[{"name":"stdout","text":"âœ… Folder zipped as /kaggle/working/predict.zip\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}